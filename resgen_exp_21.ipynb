{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.models import vgg19\n",
    "import functools\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage import img_as_float, img_as_uint\n",
    "from skimage.measure import compare_psnr\n",
    "from skimage.transform import resize\n",
    "from skimage.measure import compare_psnr\n",
    "import cv2\n",
    "\n",
    "from artificial_bluring import blur_img\n",
    "from IPython import display\n",
    "\n",
    "from copy import deepcopy\n",
    "#from models.instancenormrs import *\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from utils import *\n",
    "from network_models import *\n",
    "from traintest import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('tbruns/exp21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_path = 'coco/unlabeled2017/'\n",
    "coco_files = np.random.choice(os.listdir(coco_path), size=1500, replace=False)\n",
    "coco_files_train = coco_files[:1000]\n",
    "coco_files_test = coco_files[1000:]\n",
    "\n",
    "coco_files_train = list(map(lambda x: coco_path+x, coco_files_train))\n",
    "coco_files_test = list(map(lambda x: coco_path+x, coco_files_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = GOPRO_extended(include_sharp=0, include_coco=None,#{'train':coco_files_train, 'test':coco_files_test}, \n",
    "                      returnLP=3,\n",
    "                      desired_shape=None,\n",
    "                      transform=False,\n",
    "                      crop=(256,256))\n",
    "\n",
    "data = torch.utils.data.DataLoader(data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = GOPRO_extended(include_sharp=0,\n",
    "                           train=False,\n",
    "                           include_coco=None,#{'train':coco_files_train, 'test':coco_files_test}, \n",
    "                           returnLP=3,\n",
    "                           transform=False,\n",
    "                           desired_shape=([360,480],[640]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data2 = GOPRO_extended(include_sharp=0,\n",
    "                           train=True,\n",
    "                           include_coco=None,#{'train':coco_files_train, 'test':coco_files_test}, \n",
    "                           returnLP=3,\n",
    "                           transform=False,\n",
    "                           desired_shape=([360,480],[640]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_layer = get_norm_layer()\n",
    "\n",
    "D = NLayerDiscriminatorRF(input_nc=3, n_layers=4, ndf=128, norm_layer=norm_layer, gpu_ids=[0,1,2])\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "D.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_arg = {'input_nc':3, 'input_enc':9, 'output_nc':3, 'ngf':128, 'norm_layer':norm_layer,\n",
    "           'use_dropout':True, 'n_blocks':9, 'gpu_ids':[0,1,2], 'use_parallel':False,\n",
    "           'learn_residual':True, 'padding_type':'zero', 'partial_downsample':False}\n",
    "\n",
    "G = ResnetGenerator(**gen_arg)\n",
    "G.cuda();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lr_g=1e-5\n",
    "init_lr_d=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optD = torch.optim.Adam(D.parameters(), lr=init_lr_d)#,betas=(0., 0.5)#, weight_decay=1e-4)\n",
    "optG = torch.optim.Adam(G.parameters(), lr=init_lr_g)#,betas=(0., 0.5)#, weight_decay=1e-4)\n",
    "\n",
    "pepceptual = PerceptualLoss()\n",
    "pepceptual.initialize(loss=nn.MSELoss())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "G.load_state_dict(torch.load('ResGen_exp21.pth'))\n",
    "D.load_state_dict(torch.load('ResDisc_exp21.pth'))\n",
    "\n",
    "optG.load_state_dict(torch.load('optG_exp21.pth'))\n",
    "optD.load_state_dict(torch.load('optD_exp21.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PatchGAN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/41 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00de03a07e845e4b9e58221d4b462f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Exception in thread Thread-224:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/install/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/data/install/anaconda3/lib/python3.6/site-packages/tqdm/_monitor.py\", line 63, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/data/install/anaconda3/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n",
      "  2%|▏         | 1/41 [1:08:53<45:55:32, 4133.31s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b672c356fe448eeb528392653544615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 2/41 [2:19:44<45:25:01, 4192.34s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50bf4aa6e53466086c9f31e2e94244f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 3/41 [3:30:42<44:29:03, 4214.29s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c56063c2764c9cb12e2859b338bcfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 4/41 [4:40:34<43:15:22, 4208.72s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b161fc9fcd405380acf081c1d25f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 5/41 [5:50:10<42:01:19, 4202.20s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f607162b66c40b79b0ffbfde0ddf2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 6/41 [6:59:47<40:48:47, 4197.92s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2023dc9f644529a58616c9f835cbae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 7/41 [8:09:32<39:37:46, 4196.08s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0a51e1391740b1bb45664f38b2e03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 8/41 [9:19:07<38:26:23, 4193.44s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04afbe54cb0445ce8bb7248d36b0c397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 9/41 [10:28:40<37:15:16, 4191.14s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55dace52ec5c4a4d990054335a248f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 10/41 [11:38:15<36:04:35, 4189.54s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80f92bf60a64993badf331f3ea7790d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 11/41 [12:47:39<34:53:36, 4187.21s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0842790f02df480491c0cf705a47134e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 12/41 [13:56:18<33:41:03, 4181.50s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e6464d37534a8b90aa2253ff26d515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 13/41 [15:05:05<32:29:24, 4177.31s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428048ce764c4d55ac94051881939f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 14/41 [16:12:31<31:15:34, 4167.95s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9d528855ee4c059b48736faf644150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 15/41 [17:18:49<30:00:37, 4155.27s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ccfcb4fc61345ac9955cbdad0788203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 16/41 [18:24:43<28:46:07, 4142.71s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97f861be967499d8bc98b84ae33527a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████▏     | 17/41 [19:30:58<27:33:08, 4132.86s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a781d4f55264fafb181f41c23c04d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 18/41 [20:37:00<26:20:37, 4123.35s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "974d00c3b4054734b9afc7c022345aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▋     | 19/41 [21:43:52<25:09:45, 4117.50s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8ea15b9e5c423da38d577a18d04a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 20/41 [22:50:24<23:58:56, 4111.24s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3863f1929ba948daad97316ae9e6c17d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 21/41 [23:58:48<22:50:17, 4110.87s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641f20a27ec64261977d4a123ce51f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/install/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/data/install/anaconda3/lib/python3.6/site-packages/tensorboardX/event_file_writer.py\", line 189, in run\n",
      "    self._ev_writer.write_event(event)\n",
      "  File \"/data/install/anaconda3/lib/python3.6/site-packages/tensorboardX/event_file_writer.py\", line 71, in write_event\n",
      "    return self._write_serialized_event(event.SerializeToString())\n",
      "  File \"/data/install/anaconda3/lib/python3.6/site-packages/tensorboardX/event_file_writer.py\", line 75, in _write_serialized_event\n",
      "    self._py_recordio_writer.write(event_str)\n",
      "  File \"/data/install/anaconda3/lib/python3.6/site-packages/tensorboardX/record_writer.py\", line 31, in write\n",
      "    self._writer.flush()\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n"
     ]
    }
   ],
   "source": [
    "levelLP = -1\n",
    "kd=5\n",
    "kg=1\n",
    "disc_losses, gen_losses, psnrs, mses = list(),list(),list(),list()\n",
    "anomal_pos, anomal_neg, peaks = [],[],[]\n",
    "for epoch in tqdm(range(259,300)):\n",
    "    \n",
    "    #train\n",
    "    D.train(True)\n",
    "    G.train(True)\n",
    "    for i, ((blurred_LP,blurred), (sharp_LP, sharp)) in tqdm_notebook(enumerate(data)):\n",
    "        \n",
    "        target = sharp_LP[levelLP]\n",
    "        main_blurred, aux_blurred = get_network_tensors(blurred_LP, base_lvl=levelLP)\n",
    "\n",
    "        #update discriminator\n",
    "        for _ in range(kd):\n",
    "            \n",
    "            #Calculate critic loss\n",
    "            X_fake = G(Variable(main_blurred).cuda(),Variable(aux_blurred).cuda())\n",
    "            #X_fake_noise = torch.randn_like(X_fake)\n",
    "            X_fake_noise = X_fake# + X_fake_noise/np.random.randint(20,50)\n",
    "            \n",
    "            #if np.random.rand() < 0.3:\n",
    "            #    X_fake_noise = torch.transpose(X_fake_noise, dim0=2, dim1=3)\n",
    "\n",
    "            X_real = Variable(target).cuda()\n",
    "            #X_real_noise = torch.randn_like(X_real)\n",
    "            X_real_noise = X_real# + X_real_noise/np.random.randint(20,50)\n",
    "            \n",
    "            #if np.random.rand() < 0.3:\n",
    "            #    X_real_noise = torch.transpose(X_real_noise, dim0=2, dim1=3)\n",
    "            \n",
    "            critic_loss = D(X_fake_noise).mean() - D(X_real_noise).mean()\n",
    "            \n",
    "            #Calculate GP\n",
    "            eps = torch.rand(1, 1)\n",
    "            eps = eps.expand(X_real_noise.size())\n",
    "            eps = eps.cuda()\n",
    "\n",
    "            interpolates = eps*X_real_noise + ((1-eps)*X_fake_noise)\n",
    "            interpolates = interpolates.cuda()\n",
    "            interpolates = Variable(interpolates, requires_grad=True)\n",
    "            \n",
    "            D_interpolates = D(interpolates)\n",
    "            grad = autograd.grad(outputs=D_interpolates, inputs=interpolates,\n",
    "                                 grad_outputs=torch.ones(D_interpolates.size()).cuda(),\n",
    "                                 create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "            GP = 10*torch.pow(grad.norm(2, dim=1)-1,2).mean()\n",
    "            \n",
    "            #Do update\n",
    "            Dloss = critic_loss + GP\n",
    "            D.zero_grad()\n",
    "            Dloss.backward(retain_graph=True)\n",
    "            optD.step()\n",
    "            \n",
    "            writer.add_scalar('critic loss', critic_loss, global_step=i)\n",
    "            writer.add_scalar('GPs', GP, global_step=i)\n",
    "            writer.add_scalar('D_loss', Dloss.item(), global_step=i)\n",
    "            \n",
    "            disc_losses.append(Dloss.item())\n",
    "            if len(disc_losses)>2:\n",
    "                del disc_losses[0]\n",
    "            \n",
    "            if disc_losses==2:\n",
    "                delta=disc_losses[0]-disc_losses[1]\n",
    "                if np.abs(delta)>=80:\n",
    "                    peaks.append(delta)\n",
    "                    if delta>0:\n",
    "                        anomal_pos.append((X_fake, X_real))\n",
    "                    else:\n",
    "                        anomal_neg.append((X_fake, X_real))\n",
    "                    print('anomal')\n",
    "                    \n",
    "        #update generator\n",
    "        for _ in range(kg):\n",
    "            X_fake = G(Variable(main_blurred).cuda(),Variable(aux_blurred).cuda())\n",
    "\n",
    "            content_loss = pepceptual.get_loss(X_fake, X_real)\n",
    "            Adv_loss = -D(X_fake).mean()\n",
    "            Gloss = Adv_loss + 0.5*content_loss\n",
    "\n",
    "            G.zero_grad()\n",
    "            Gloss.backward()\n",
    "            optG.step()\n",
    "\n",
    "            writer.add_scalar('Gen loss', Gloss.item(), global_step=i)\n",
    "            writer.add_scalar('Gen adv loss', Adv_loss.item(), global_step=i)\n",
    "            writer.add_scalar('Gen content loss', 0.5*content_loss.item(), global_step=i)\n",
    "        \n",
    "    #Dynamic lr\n",
    "    if epoch>150:\n",
    "        optD.param_groups[0]['lr'] = optD.param_groups[0]['lr'] - init_lr_d/150\n",
    "        optG.param_groups[0]['lr'] = optG.param_groups[0]['lr'] - init_lr_g/150\n",
    "            \n",
    "    #Save\n",
    "    torch.save(G.state_dict(), 'ResGen_exp21.pth')\n",
    "    torch.save(D.state_dict(), 'ResDisc_exp21.pth')\n",
    "    torch.save(optG.state_dict(), 'optG_exp21.pth')\n",
    "    torch.save(optD.state_dict(), 'optD_exp21.pth')\n",
    "    \n",
    "    #test\n",
    "    (recon,gt,orig), psnr, _ = test_deblurring_cur(net={'lvl3_net':G, 'lvl2_net':None, 'lvl1_net':None},\n",
    "                                                   test_dataset=test_data,\n",
    "                                                   lvl=[3],\n",
    "                                                   return_sharp_blurred=True)\n",
    "    \n",
    "        \n",
    "    recon_lap_vis = get_laplacian_pyramid(recon)[-1].clip(0,1)\n",
    "    gt_lap_vis = get_laplacian_pyramid(gt)[-1].clip(0,1)\n",
    "    \n",
    "    writer.add_image('recon_lp_test', torch.FloatTensor(np.transpose(recon_lap_vis, [2,0,1])), epoch)\n",
    "    writer.add_image('gt_lp_test', torch.FloatTensor(np.transpose(gt_lap_vis, [2,0,1])), epoch)\n",
    "    writer.add_scalar('PSNRs', psnr, global_step=epoch)\n",
    "    \n",
    "    #test on train\n",
    "    (recon,gt,orig), psnr, _ = test_deblurring_cur(net={'lvl3_net':G, 'lvl2_net':None, 'lvl1_net':None},\n",
    "                                                   test_dataset=test_data2,\n",
    "                                                   lvl=[3],\n",
    "                                                   return_sharp_blurred=True)\n",
    "    \n",
    "    recon_lap_vis = get_laplacian_pyramid(recon)[-1].clip(0,1)\n",
    "    gt_lap_vis = get_laplacian_pyramid(gt)[-1].clip(0,1)\n",
    "    \n",
    "    writer.add_image('recon_lp_train', torch.FloatTensor(np.transpose(recon_lap_vis, [2,0,1])), epoch)\n",
    "    writer.add_image('gt_lp_train', torch.FloatTensor(np.transpose(gt_lap_vis, [2,0,1])), epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
