{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.models import vgg19\n",
    "import functools\n",
    "\n",
    "from skimage.io import imread, imsave\n",
    "from skimage import img_as_float, img_as_uint\n",
    "from skimage.measure import compare_psnr\n",
    "from skimage.transform import resize\n",
    "from skimage.measure import compare_psnr\n",
    "import cv2\n",
    "\n",
    "from artificial_bluring import blur_img\n",
    "from IPython import display\n",
    "\n",
    "from copy import deepcopy\n",
    "#from models.instancenormrs import *\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from utils import *\n",
    "from network_models import *\n",
    "from traintest import *\n",
    "from unet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('tbruns/uexp1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_path = 'coco/unlabeled2017/'\n",
    "coco_files = np.random.choice(os.listdir(coco_path), size=1500, replace=False)\n",
    "coco_files_train = coco_files[:1000]\n",
    "coco_files_test = coco_files[1000:]\n",
    "\n",
    "coco_files_train = list(map(lambda x: coco_path+x, coco_files_train))\n",
    "coco_files_test = list(map(lambda x: coco_path+x, coco_files_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = GOPRO_extended(include_sharp=0, include_coco=None,#{'train':coco_files_train, 'test':coco_files_test}, \n",
    "                      returnLP=3,\n",
    "                      desired_shape=None,\n",
    "                      transform=False,\n",
    "                      crop=(256,256))\n",
    "\n",
    "data = torch.utils.data.DataLoader(data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = GOPRO_extended(include_sharp=0,\n",
    "                           train=False,\n",
    "                           include_coco=None,#{'train':coco_files_train, 'test':coco_files_test}, \n",
    "                           returnLP=3,\n",
    "                           transform=False,\n",
    "                           crop=None,\n",
    "                           desired_shape=([360,480],[640]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data2 = GOPRO_extended(include_sharp=0,\n",
    "                           train=True,\n",
    "                           include_coco=None,#{'train':coco_files_train, 'test':coco_files_test}, \n",
    "                           returnLP=3,\n",
    "                           transform=False,\n",
    "                           desired_shape=([360,480],[640]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_layer = get_norm_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = NLayerDiscriminatorRF(input_nc=3, n_layers=4, ndf=128, norm_layer=norm_layer, gpu_ids=[0,1,2])\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "D.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = UNetGenerator(input_nc=6, output_nc=3, ngf=64, norm_layer=norm_layer)\n",
    "G.cuda();"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "G.load_state_dict(torch.load('unet_gen_exp1.pth'))\n",
    "D.load_state_dict(torch.load('unet_disc_exp1.pth'))\n",
    "optG.load_state_dict(torch.load('uoptG_exp1.pth'))\n",
    "optD.load_state_dict(torch.load('uoptD_exp1.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lr_g=1e-4\n",
    "init_lr_d=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optD = torch.optim.Adam(D.parameters(), lr=init_lr_d)#,betas=(0., 0.5)#, weight_decay=1e-4)\n",
    "optG = torch.optim.Adam(G.parameters(), lr=init_lr_g)#,betas=(0., 0.5)#, weight_decay=1e-4)\n",
    "\n",
    "pepceptual = PerceptualLoss()\n",
    "pepceptual.initialize(loss=nn.MSELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optD.param_groups[0]['lr'] = 1e-5\n",
    "optG.param_groups[0]['lr'] = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PatchGAN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/166 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a426ae4ff8404090cb40a1a3d6227e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:65: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: This function is deprecated. Please call randint(0, 2 + 1) instead\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: This function is deprecated. Please call randint(0, 3 + 1) instead\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: This function is deprecated. Please call randint(0, 4 + 1) instead\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: This function is deprecated. Please call randint(0, 5 + 1) instead\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: This function is deprecated. Please call randint(0, 6 + 1) instead\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: This function is deprecated. Please call randint(0, 7 + 1) instead\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: This function is deprecated. Please call randint(0, 8 + 1) instead\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: This function is deprecated. Please call randint(0, 9 + 1) instead\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: This function is deprecated. Please call randint(0, 10 + 1) instead\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: This function is deprecated. Please call randint(0, 11 + 1) instead\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: This function is deprecated. Please call randint(0, 12 + 1) instead\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: This function is deprecated. Please call randint(0, 13 + 1) instead\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: This function is deprecated. Please call randint(0, 14 + 1) instead\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: This function is deprecated. Please call randint(0, 15 + 1) instead\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: This function is deprecated. Please call randint(0, 16 + 1) instead\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: This function is deprecated. Please call randint(0, 17 + 1) instead\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: This function is deprecated. Please call randint(0, 18 + 1) instead\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: This function is deprecated. Please call randint(0, 19 + 1) instead\n",
      "/data/install/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning: This function is deprecated. Please call randint(0, 20 + 1) instead\n"
     ]
    }
   ],
   "source": [
    "levelLP = -1\n",
    "kd=5\n",
    "kg=1\n",
    "disc_losses, gen_losses, psnrs, mses = list(),list(),list(),list()\n",
    "reals, fakes = [],[]\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(134,300)):\n",
    "    \n",
    "    #train\n",
    "    D.train(True)\n",
    "    G.train(True)\n",
    "    for i, ((blurred_LP,blurred), (sharp_LP, sharp)) in tqdm_notebook(enumerate(data)):\n",
    "        \n",
    "        target = sharp_LP[levelLP]\n",
    "        \n",
    "        main_blurred = blurred_LP[levelLP]\n",
    "        blurred_img = blurred.transpose(dim0=2, dim1=3).transpose(dim0=1, dim1=2).float()\n",
    "        main_blurred = torch.cat([main_blurred, blurred_img],1)\n",
    "        \n",
    "        #update discriminator\n",
    "        for _ in range(kd):\n",
    "            \n",
    "            #Calculate critic loss\n",
    "            X_fake = G(Variable(main_blurred).cuda())\n",
    "            X_fake_noise = torch.randn_like(X_fake)\n",
    "            X_fake_noise = X_fake + X_fake_noise/np.random.randint(20,50)\n",
    "    \n",
    "\n",
    "            X_real = Variable(target).cuda()\n",
    "            X_real_noise = torch.randn_like(X_real)\n",
    "            X_real_noise = X_real + X_real_noise/np.random.randint(20,50)\n",
    "    \n",
    "            \n",
    "            critic_loss = D(X_fake_noise).mean() - D(X_real_noise).mean()\n",
    "            \n",
    "            #Calculate GP\n",
    "            eps = torch.rand(1, 1)\n",
    "            eps = eps.expand(X_real_noise.size())\n",
    "            eps = eps.cuda()\n",
    "\n",
    "            interpolates = eps*X_real_noise + ((1-eps)*X_fake_noise)\n",
    "            interpolates = interpolates.cuda()\n",
    "            interpolates = Variable(interpolates, requires_grad=True)\n",
    "            \n",
    "            D_interpolates = D(interpolates)\n",
    "            grad = autograd.grad(outputs=D_interpolates, inputs=interpolates,\n",
    "                                 grad_outputs=torch.ones(D_interpolates.size()).cuda(),\n",
    "                                 create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "            GP = 10*torch.pow(grad.norm(2, dim=1)-1,2).mean()\n",
    "            \n",
    "            #Do update\n",
    "            Dloss = critic_loss + GP\n",
    "            D.zero_grad()\n",
    "            Dloss.backward(retain_graph=True)\n",
    "            optD.step()\n",
    "            \n",
    "            writer.add_scalar('critic loss', critic_loss, global_step=i)\n",
    "            writer.add_scalar('GPs', GP, global_step=i)\n",
    "            writer.add_scalar('D_loss', Dloss.item(), global_step=i)\n",
    "            \n",
    "        if len(fakes)>=2:\n",
    "            idxs = [np.random.random_integers(0, len(fakes)-1, size=np.random.randint(0, len(fakes)//2))]\n",
    "            for fake_buf,reals_buf in np.array(list(zip(fakes, reals)), dtype=np.object)[idxs]:\n",
    "\n",
    "                if np.random.rand()<0.5:\n",
    "                    X_fake_noise = torch.randn_like(fake_buf)\n",
    "                    X_fake_noise = fake_buf + X_fake_noise/np.random.randint(20,50)\n",
    "                else:\n",
    "                    X_fake_noise = fake_buf\n",
    "\n",
    "                if np.random.rand()<0.5:\n",
    "                    X_real_noise = torch.randn_like(reals_buf)\n",
    "                    X_real_noise = reals_buf + X_real_noise/np.random.randint(20,50)\n",
    "                else:\n",
    "                    X_real_noise = reals_buf\n",
    "\n",
    "                critic_loss = D(X_fake_noise).mean() - D(X_real_noise).mean()\n",
    "\n",
    "                #Calculate GP\n",
    "                eps = torch.rand(1, 1)\n",
    "                eps = eps.expand(X_real_noise.size())\n",
    "                eps = eps.cuda()\n",
    "\n",
    "                interpolates = eps*X_real_noise + ((1-eps)*X_fake_noise)\n",
    "                interpolates = interpolates.cuda()\n",
    "                interpolates = Variable(interpolates, requires_grad=True)\n",
    "\n",
    "                D_interpolates = D(interpolates)\n",
    "                grad = autograd.grad(outputs=D_interpolates, inputs=interpolates,\n",
    "                                     grad_outputs=torch.ones(D_interpolates.size()).cuda(),\n",
    "                                     create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "                GP = 10*torch.pow(grad.norm(2, dim=1)-1,2).mean()\n",
    "\n",
    "                #Do update\n",
    "                Dloss = critic_loss + GP\n",
    "                D.zero_grad()\n",
    "                Dloss.backward(retain_graph=True)\n",
    "                optD.step()\n",
    "\n",
    "        #update generator\n",
    "        for _ in range(kg):\n",
    "            X_fake = G(Variable(main_blurred).cuda())\n",
    "\n",
    "            content_loss = pepceptual.get_loss(X_fake, X_real)\n",
    "            Adv_loss = -D(X_fake).mean()\n",
    "            Gloss = Adv_loss + 0.5*content_loss\n",
    "\n",
    "            G.zero_grad()\n",
    "            Gloss.backward()\n",
    "            optG.step()\n",
    "\n",
    "            writer.add_scalar('Gen loss', Gloss.item(), global_step=i)\n",
    "            writer.add_scalar('Gen Wasserstein loss', Adv_loss.item(), global_step=i)\n",
    "            writer.add_scalar('Gen content loss', content_loss.item(), global_step=i)\n",
    "        \n",
    "        \n",
    "        if len(fakes)>20:\n",
    "            rm = np.random.randint(0,len(fakes))\n",
    "            del fakes[rm]\n",
    "            del reals[rm]\n",
    "        \n",
    "        fakes.append(X_fake.detach())\n",
    "        reals.append(X_real.detach())\n",
    "        \n",
    "    #Dynamic lr\n",
    "    if epoch>150:\n",
    "        optD.param_groups[0]['lr'] = optD.param_groups[0]['lr'] - init_lr_d/150\n",
    "        optG.param_groups[0]['lr'] = optG.param_groups[0]['lr'] - init_lr_g/150\n",
    "            \n",
    "    #Save\n",
    "    torch.save(G.state_dict(), 'unet_gen_exp1.pth')\n",
    "    torch.save(D.state_dict(), 'unet_disc_exp1.pth')\n",
    "    torch.save(optG.state_dict(), 'uoptG_exp1.pth')\n",
    "    torch.save(optD.state_dict(), 'uoptD_exp1.pth')\n",
    "    \n",
    "    #test\n",
    "    (recon,gt,orig), psnr, _ = test_deblurring_unet(net={'lvl3_net':G, 'lvl2_net':None, 'lvl1_net':None},\n",
    "                                                   test_dataset=test_data,\n",
    "                                                   lvl=[3],\n",
    "                                                   return_sharp_blurred=True)\n",
    "    \n",
    "        \n",
    "    recon_lap_vis = get_laplacian_pyramid(recon)[-1].clip(0,1)\n",
    "    gt_lap_vis = get_laplacian_pyramid(gt)[-1].clip(0,1)\n",
    "    \n",
    "    writer.add_image('recon_lp_test', torch.FloatTensor(np.transpose(recon_lap_vis, [2,0,1])), epoch)\n",
    "    writer.add_image('gt_lp_test', torch.FloatTensor(np.transpose(gt_lap_vis, [2,0,1])), epoch)\n",
    "    writer.add_scalar('PSNRs', psnr, global_step=epoch)\n",
    "    \n",
    "    #test on train\n",
    "    (recon,gt,orig), psnr, _ = test_deblurring_unet(net={'lvl3_net':G, 'lvl2_net':None, 'lvl1_net':None},\n",
    "                                                   test_dataset=test_data2,\n",
    "                                                   lvl=[3],\n",
    "                                                   return_sharp_blurred=True)\n",
    "    \n",
    "    recon_lap_vis = get_laplacian_pyramid(recon)[-1].clip(0,1)\n",
    "    gt_lap_vis = get_laplacian_pyramid(gt)[-1].clip(0,1)\n",
    "    \n",
    "    writer.add_image('recon_lp_train', torch.FloatTensor(np.transpose(recon_lap_vis, [2,0,1])), epoch)\n",
    "    writer.add_image('gt_lp_train', torch.FloatTensor(np.transpose(gt_lap_vis, [2,0,1])), epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
